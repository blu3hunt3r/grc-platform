/**
 * @file supabase-setup.ts
 * @description Complete automated Supabase configuration via CLI and API
 * @architecture Reference: Part 2 - Database & Data Flow, Part 6 - Security & Testing
 *
 * This script automates ALL Supabase configuration:
 * - Storage bucket creation with RLS policies
 * - Realtime enablement with RLS policies
 * - Database migration execution
 *
 * NO MANUAL STEPS REQUIRED - Complete production-grade automation
 *
 * Usage: pnpm tsx scripts/setup/supabase-setup.ts
 */

import { createClient } from '@supabase/supabase-js';
import { readFileSync } from 'fs';
import { join } from 'path';
import { execSync } from 'child_process';

// Configuration from environment
const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL || 'https://pmrnysbgingvqignadhw.supabase.co';
const SUPABASE_SERVICE_ROLE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;
const DATABASE_URL = 'postgresql://postgres:my-first-love@aws-0-us-east-1.pooler.supabase.com:6543/postgres?pgbouncer=true&connection_limit=1';

if (!SUPABASE_SERVICE_ROLE_KEY) {
  console.error('‚ùå SUPABASE_SERVICE_ROLE_KEY environment variable is required');
  console.error('   Get it from: Supabase Dashboard ‚Üí Settings ‚Üí API ‚Üí service_role key');
  process.exit(1);
}

// Initialize Supabase admin client
const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, {
  auth: {
    autoRefreshToken: false,
    persistSession: false,
  },
});

/**
 * Storage bucket configuration
 * Architecture Reference: SYSTEM_PROMPT.md Line 73 - "Three buckets (evidence-files, policy-documents, audit-reports)"
 */
const STORAGE_BUCKETS = [
  {
    id: 'evidence-files',
    name: 'evidence-files',
    public: false,
    fileSizeLimit: 52428800, // 50MB
    allowedMimeTypes: ['image/*', 'application/pdf', 'video/*'],
  },
  {
    id: 'policy-documents',
    name: 'policy-documents',
    public: false,
    fileSizeLimit: 10485760, // 10MB
    allowedMimeTypes: ['application/pdf', 'application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'text/*'],
  },
  {
    id: 'audit-reports',
    name: 'audit-reports',
    public: false,
    fileSizeLimit: 26214400, // 25MB
    allowedMimeTypes: ['application/pdf'],
  },
];

/**
 * Step 1: Create storage buckets
 */
async function createStorageBuckets(): Promise<void> {
  console.log('\nüì¶ Creating storage buckets...');

  for (const bucket of STORAGE_BUCKETS) {
    try {
      // Check if bucket exists
      const { data: existingBucket } = await supabase.storage.getBucket(bucket.id);

      if (existingBucket) {
        console.log(`   ‚úì Bucket "${bucket.id}" already exists`);

        // Update bucket configuration
        const { error: updateError } = await supabase.storage.updateBucket(bucket.id, {
          public: bucket.public,
          fileSizeLimit: bucket.fileSizeLimit,
          allowedMimeTypes: bucket.allowedMimeTypes,
        });

        if (updateError) {
          console.error(`   ‚ùå Failed to update bucket "${bucket.id}":`, updateError.message);
        } else {
          console.log(`   ‚úì Updated bucket "${bucket.id}" configuration`);
        }
      } else {
        // Create new bucket
        const { error: createError } = await supabase.storage.createBucket(bucket.id, {
          public: bucket.public,
          fileSizeLimit: bucket.fileSizeLimit,
          allowedMimeTypes: bucket.allowedMimeTypes,
        });

        if (createError) {
          console.error(`   ‚ùå Failed to create bucket "${bucket.id}":`, createError.message);
        } else {
          console.log(`   ‚úì Created bucket "${bucket.id}" (${bucket.fileSizeLimit / 1024 / 1024}MB limit)`);
        }
      }
    } catch (error) {
      console.error(`   ‚ùå Error with bucket "${bucket.id}":`, error);
    }
  }
}

/**
 * Step 2: Execute SQL files via psql
 */
async function executeSQLFiles(): Promise<void> {
  console.log('\nüóÑÔ∏è  Executing SQL migration files...');

  const sqlFiles = [
    {
      path: join(__dirname, '../../packages/database/migrate-clerkid-to-authid.sql'),
      description: 'Migrate clerkId ‚Üí authId column',
      optional: true, // Only needed if data exists
    },
    {
      path: join(__dirname, '../../packages/database/supabase-storage-setup.sql'),
      description: 'Storage bucket RLS policies',
      optional: false,
    },
    {
      path: join(__dirname, '../../packages/database/supabase-realtime-setup.sql'),
      description: 'Realtime RLS policies',
      optional: false,
    },
  ];

  for (const file of sqlFiles) {
    try {
      console.log(`\n   ‚Üí Executing: ${file.description}`);
      console.log(`     File: ${file.path}`);

      const sql = readFileSync(file.path, 'utf-8');

      // Execute via Supabase RPC (for DDL statements)
      const { error } = await supabase.rpc('exec_sql', { sql_string: sql });

      if (error) {
        if (file.optional) {
          console.log(`   ‚ö†Ô∏è  Optional migration skipped: ${error.message}`);
        } else {
          console.error(`   ‚ùå Failed to execute ${file.description}: ${error.message}`);
          console.error(`   ‚Üí Falling back to direct psql execution...`);

          // Fallback: Execute via psql CLI
          try {
            execSync(
              `PGPASSWORD='my-first-love' psql -h aws-0-us-east-1.pooler.supabase.com -p 6543 -U postgres -d postgres -f "${file.path}"`,
              { stdio: 'inherit', encoding: 'utf-8' }
            );
            console.log(`   ‚úì Executed via psql: ${file.description}`);
          } catch (psqlError) {
            console.error(`   ‚ùå psql execution failed:`, psqlError);
          }
        }
      } else {
        console.log(`   ‚úì Executed: ${file.description}`);
      }
    } catch (error) {
      console.error(`   ‚ùå Error executing ${file.description}:`, error);
    }
  }
}

/**
 * Step 3: Enable realtime for tables
 */
async function enableRealtime(): Promise<void> {
  console.log('\nüî¥ Enabling realtime for tables...');

  const tables = ['agent_executions', 'audits', 'tasks', 'evidence', 'approvals'];

  for (const table of tables) {
    try {
      // Enable realtime via SQL
      const { error } = await supabase.rpc('exec_sql', {
        sql_string: `ALTER PUBLICATION supabase_realtime ADD TABLE ${table};`,
      });

      if (error) {
        console.log(`   ‚ö†Ô∏è  Table "${table}" realtime: ${error.message} (may already be enabled)`);
      } else {
        console.log(`   ‚úì Enabled realtime for table: ${table}`);
      }
    } catch (error) {
      console.error(`   ‚ùå Error enabling realtime for "${table}":`, error);
    }
  }
}

/**
 * Step 4: Verify configuration
 */
async function verifyConfiguration(): Promise<void> {
  console.log('\n‚úÖ Verifying configuration...');

  // Verify storage buckets
  const { data: buckets, error: bucketsError } = await supabase.storage.listBuckets();
  if (bucketsError) {
    console.error('   ‚ùå Failed to list buckets:', bucketsError.message);
  } else {
    console.log(`   ‚úì Storage buckets: ${buckets.length} total`);
    for (const bucket of STORAGE_BUCKETS) {
      const exists = buckets.some((b) => b.id === bucket.id);
      console.log(`     ${exists ? '‚úì' : '‚ùå'} ${bucket.id}`);
    }
  }

  // Verify database connection
  const { data: testQuery, error: testError } = await supabase
    .from('users')
    .select('count')
    .limit(1);

  if (testError && testError.code !== 'PGRST116') { // PGRST116 = table not found (acceptable)
    console.error('   ‚ùå Database connection failed:', testError.message);
  } else {
    console.log('   ‚úì Database connection working');
  }
}

/**
 * Main execution
 */
async function main(): Promise<void> {
  console.log('üöÄ Supabase Setup - Complete Automation');
  console.log('==========================================');
  console.log(`Project: ${SUPABASE_URL}`);
  console.log(`Database: ${DATABASE_URL.split('@')[1].split('?')[0]}`);

  try {
    // Step 1: Create storage buckets
    await createStorageBuckets();

    // Step 2: Execute SQL files
    await executeSQLFiles();

    // Step 3: Enable realtime
    await enableRealtime();

    // Step 4: Verify configuration
    await verifyConfiguration();

    console.log('\n‚úÖ Supabase setup complete!');
    console.log('\nNext steps:');
    console.log('1. Run tests: pnpm --filter @grc/database test');
    console.log('2. Deploy: pnpm deploy');

    process.exit(0);
  } catch (error) {
    console.error('\n‚ùå Setup failed:', error);
    process.exit(1);
  }
}

// Execute if run directly
if (require.main === module) {
  main();
}

export { main as setupSupabase };
